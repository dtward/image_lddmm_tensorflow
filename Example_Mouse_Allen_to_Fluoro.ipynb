{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mouse Allen to fluoro example\n",
    "\n",
    "This example maps betwen the allen CCF mouse atlas and fluorescence mouse image.\n",
    "\n",
    "Here we will use affine alignment in adition to deformable registration.  \n",
    "\n",
    "Affine will be performed first, then both will be performed simultaneously.\n",
    "\n",
    "Also we will estimate artifact locations using the EM algorithm and compensate for them in our matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports\n",
    "We start by importing necessary libraries.  That includes numpy, matplotlib, and tensorflow for numerical work, nibabel for loading neuroimages, and lddmm and vis which are part of this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for arrays\n",
    "%matplotlib notebook\n",
    "import matplotlib as mpl # for graphics\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib # for loading neuroimages\n",
    "import lddmm # algorithm\n",
    "import vis # visualization\n",
    "import tensorflow as tf\n",
    "import imp # use imp.reload to update modules during development\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure GPU is not recognised\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorFlow backend uses all available GPU memory by default, hence it can be useful to limit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get filenames\n",
    "atlas_image_fname = 'average_template_50.img'\n",
    "target_image_fname = '180517_Downsample.img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load them with nibabel\n",
    "fnames = [atlas_image_fname,target_image_fname]\n",
    "img = [nib.load(fname) for fname in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info about image space\n",
    "if '.img' == atlas_image_fname[-4:]:    \n",
    "    nxI = img[0].header['dim'][1:4]\n",
    "    dxI = img[0].header['pixdim'][1:4]\n",
    "    nxJ = img[1].header['dim'][1:4]\n",
    "    dxJ = img[1].header['pixdim'][1:4]\n",
    "else:\n",
    "    # I'm only working with analyze for now\n",
    "    raise ValueError('Only Analyze images supported for now')\n",
    "xI = [np.arange(nxi)*dxi - np.mean(np.arange(nxi)*dxi) for nxi,dxi in zip(nxI,dxI)]\n",
    "xJ = [np.arange(nxi)*dxi - np.mean(np.arange(nxi)*dxi) for nxi,dxi in zip(nxJ,dxJ)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the images, note they also include a fourth axis for time that I don't want\n",
    "I = img[0].get_data()[:,:,:,0]\n",
    "J = img[1].get_data()[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would like to pad one slice of the allen atlas so that it has zero boundary conditions\n",
    "zeroslice = np.zeros((nxI[0],1,nxI[2]))\n",
    "I = np.concatenate((I,zeroslice),axis=1)\n",
    "nxI = img[0].header['dim'][1:4]\n",
    "nxI[1] += 1\n",
    "xI = [np.arange(nxi)*dxi - np.mean(np.arange(nxi)*dxi) for nxi,dxi in zip(nxI,dxI)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the data\n",
    "f = plt.figure()\n",
    "vis.imshow_slices(I, x=xI, fig=f)\n",
    "f.suptitle('Atlas I')\n",
    "f.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "vis.imshow_slices(J,x=xJ,fig=f)\n",
    "f.suptitle('Target J')\n",
    "f.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this image has a giant bright spot.  This is an artifact we will need to compensate for in order to do accurate registration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorientation\n",
    "The allen atlas is not stored in the same orientation as our data, we will specify an initial affine transformation to put it in the correct transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the line below is a good initial orientation\n",
    "A = np.array([[0,0,1,0],\n",
    "              [-1,0,0,0],\n",
    "              [0,1,0,0],\n",
    "              [0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken and adapted from https://github.com/CSBDeep/CSBDeep/blob/master/csbdeep/utils/tf.py and utils.py\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Lambda\n",
    "\n",
    "def is_tf_backend():\n",
    "    import keras.backend as K\n",
    "    return K.backend() == 'tensorflow'\n",
    "\n",
    "\n",
    "def limit_gpu_memory(fraction, allow_growth=False):\n",
    "    \"\"\"Limit GPU memory allocation for TensorFlow (TF) backend.\n",
    "    Parameters\n",
    "    ----------\n",
    "    fraction : float\n",
    "        Limit TF to use only a fraction (value between 0 and 1) of the available GPU memory.\n",
    "        Reduced memory allocation can be disabled if fraction is set to ``None``.\n",
    "    allow_growth : bool, optional\n",
    "        If ``False`` (default), TF will allocate all designated (see `fraction`) memory all at once.\n",
    "        If ``True``, TF will allocate memory as needed up to the limit imposed by `fraction`; this may\n",
    "        incur a performance penalty due to memory fragmentation.\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `fraction` is not ``None`` or a float value between 0 and 1.\n",
    "    NotImplementedError\n",
    "        If TensorFlow is not used as the backend.\n",
    "    \"\"\"\n",
    "\n",
    "    is_tf_backend() or _raise(NotImplementedError('Not using tensorflow backend.'))\n",
    "    fraction is None or (np.isscalar(fraction) and 0<=fraction<=1) or _raise(ValueError('fraction must be between 0 and 1.'))\n",
    "\n",
    "    if K.tensorflow_backend._SESSION is None:\n",
    "        config = tf.ConfigProto()\n",
    "        if fraction is not None:\n",
    "            config.gpu_options.per_process_gpu_memory_fraction = fraction\n",
    "        config.gpu_options.allow_growth = bool(allow_growth)\n",
    "        session = tf.Session(config=config)\n",
    "        K.tensorflow_backend.set_session(session)\n",
    "        # print(\"[tf_limit]\\t setting config.gpu_options.per_process_gpu_memory_fraction to \",config.gpu_options.per_process_gpu_memory_fraction)\n",
    "    else:\n",
    "        warnings.warn('Too late too limit GPU memory, can only be done once and before any computation.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_gpu_memory(fraction=0.5,allow_growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test the initial affine\n",
    "X0,X1,X2 = np.meshgrid(xJ[0],xJ[1],xJ[2],indexing='ij')\n",
    "X0tf = tf.constant(X0,dtype=lddmm.dtype)\n",
    "X1tf = tf.constant(X1,dtype=lddmm.dtype)\n",
    "X2tf = tf.constant(X2,dtype=lddmm.dtype)\n",
    "Itf = tf.constant(I,dtype=lddmm.dtype)\n",
    "B = np.linalg.inv(A)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    Xs = B[0,0]*X0tf + B[0,1]*X1tf + B[0,2]*X2tf + B[0,3]\n",
    "    Ys = B[1,0]*X0tf + B[1,1]*X1tf + B[1,2]*X2tf + B[1,3]\n",
    "    Zs = B[2,0]*X0tf + B[2,1]*X1tf + B[2,2]*X2tf + B[2,3]\n",
    "    Id = lddmm.interp3(xI[0], xI[1], xI[2], Itf, Xs, Ys, Zs)\n",
    "    Idnp = Id.eval()\n",
    "f = plt.figure()\n",
    "vis.imshow_slices(Idnp,x=xJ,fig=f)\n",
    "f.suptitle('Initial affine transformation')\n",
    "f.canvas.draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DR IT MD matching\n",
    "\n",
    "Because of the artifact we will run the missing data version of the algorithm.  This can be specified by setting the `nMstep` argument to an integer grater than 0.  This parameters says how many iterations of gradient descent are used in the maximization step of the EM algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "# cost function weights 1 / sigma^2\n",
    "sigmaM = np.std(J) # matching\n",
    "sigmaA = sigmaM*10.0 # artifact\n",
    "sigmaR = 1e0 # regularization\n",
    "\n",
    "# enery operator, power of laplacian p, characteristic length a\n",
    "p = 2\n",
    "a = (xI[0][1]-xI[0][0])*5\n",
    "\n",
    "# other optimization parameters\n",
    "niter = 200 # how many iteraitons of gradient descent\n",
    "naffine = 50 # first naffine iterations are affine only (no deformation)\n",
    "nt = 5 # this many timesteps to numerically integrate flow\n",
    "# the linear part is a bit too big still (since I fixed voxel size issue)\n",
    "# initial guess for affine (check picture above)\n",
    "A0 = A\n",
    "\n",
    "# When working with weights in EM algorithm, how many M steps per E step\n",
    "# first test with 0 (it is working)\n",
    "nMstep = 5\n",
    "nMstep_affine = 1\n",
    "\n",
    "# gradient descent step size\n",
    "eL = 2e-4\n",
    "eT = 1e-3\n",
    "eV = 5e-3\n",
    "# I think maybe eV has to be bigger\n",
    "eV = 1e-2\n",
    "# there is some oscilation in the translation and the linear part\n",
    "\n",
    "out = lddmm.lddmm(I, J, \n",
    "                  xI=xI, # location of pixels in domain\n",
    "                  xJ=xJ,                  \n",
    "                  niter=niter, # iterations of gradient descent\n",
    "                  naffine=naffine, # iterations of affine only\n",
    "                  eV = eV, # step size for deformation parameters\n",
    "                  eT = eT, # step size for translation parameters\n",
    "                  eL = eL, # step size for linear parameters\n",
    "                  nt=nt, # timesteps for integtating flow\n",
    "                  sigmaM=sigmaM, # matching cost weight 1/2sigmaM^2\n",
    "                  sigmaR=sigmaR, # reg cost weight 1/2sigmaM^2\n",
    "                  sigmaA=sigmaA, # artifact cost weight 1/2sigmaA^2\n",
    "                  a=a, # kernel width\n",
    "                  p=p, # power of laplacian in kernel (should be at least 2 for 3D)\n",
    "                  A0=A0, # initial guess for affine matrix (should get orientation right)\n",
    "                  nMstep=nMstep, # number of m steps for each e step\n",
    "                  nMstep_affine=nMstep_affine # number of m steps during affine only phase\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
